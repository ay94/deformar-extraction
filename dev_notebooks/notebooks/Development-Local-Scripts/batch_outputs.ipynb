{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import userdata\n",
    "    access_token = userdata.get('DEFORMER_TOKEN')\n",
    "    !pip install git+https://$access_token@github.com/ay94/deformer-extractor.git@error-handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_utils import colab\n",
    "from experiment_utils.general_utils import FileHandler\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-20 21:49:37 - WARNING - Resolved path does not exist, checking alternative paths: /Users/ay227/Desktop/Final-Year/Thesis-Experiments/Data-Extraction-Phase/notebooks/My Drive\n",
      "2024-07-20 21:49:37 - INFO - Found Google Drive directory for account ahmed.younes.sam@gmail.com: /Users/ay227/Library/CloudStorage/GoogleDrive-ahmed.younes.sam@gmail.com\n"
     ]
    }
   ],
   "source": [
    "base_folder = colab.init('My Drive')\n",
    "config_path = base_folder / 'Final Year Experiments/Class Imbalance/1_fineTuning'\n",
    "fh = FileHandler(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='arabertv02'\n",
    "data_name='ANERCorp_CamelLab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "training_outputs = fh.load_pickle(\n",
    "            f\"evalOutputs/{model_name}_{data_name}_regular_outputs.pkl\"\n",
    "        )\n",
    "load_model_path = fh.file_path / f\"trainOutputs/{model_name}_{data_name}_regular.bin\"\n",
    "model = torch.load(load_model_path, map_location=torch.device('cpu'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-100,    5,    5,    0,    1,    2, -100, -100,    0,    0,    0,    0,\n",
       "           1,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0, -100,    0,    0,    0,    0,    0,    0,    0,    5,    5, -100,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_outputs.test_dataloader.dataset[0]['inpy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_utils.model_outputs_utils import BatchOutputs, ModelOutputs, ModelResults, GenerateSplitBatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e195c83ed24cd0aee1549bbd1ebba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Compute Outputs\n"
     ]
    }
   ],
   "source": [
    "outputs = GenerateSplitBatches(training_outputs, model, training_outputs.test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 3.0585e-01, 2.1982e-02, 1.0366e-03, 2.2747e-02, 1.3149e-02,\n",
       "        0.0000e+00, 0.0000e+00, 5.3392e-04, 4.0292e-05, 1.0251e-04, 1.8690e-04,\n",
       "        2.0437e-03, 4.0239e-03, 4.9590e-05, 3.5405e-05, 3.8981e-05, 2.7299e-05,\n",
       "        3.9934e-05, 3.8742e-05, 6.1868e-05, 5.4358e-05, 3.1590e-05, 3.4809e-05,\n",
       "        8.4277e-05, 0.0000e+00, 6.2702e-05, 3.4570e-05, 4.5060e-05, 6.2941e-05,\n",
       "        5.5192e-05, 3.3616e-05, 5.4142e-04, 1.5900e-02, 2.2703e-01, 0.0000e+00,\n",
       "        5.4716e-05, 1.3267e-01, 8.1702e-03, 3.2782e-05, 3.7073e-05, 3.8265e-05,\n",
       "        3.6001e-05, 2.6106e-05, 1.6783e-04, 7.0212e-05, 6.6397e-05, 4.4822e-05,\n",
       "        0.0000e+00])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.outputs.aligned_losses[0][:49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels <class 'torch.Tensor'>\n",
      "words_ids <class 'torch.Tensor'>\n",
      "sentence_num <class 'torch.Tensor'>\n",
      "attention_mask <class 'torch.Tensor'>\n",
      "input_ids <class 'torch.Tensor'>\n",
      "losses <class 'torch.Tensor'>\n",
      "logits <class 'torch.Tensor'>\n",
      "last_hidden_state <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for k, v in outputs.batches[0].items():\n",
    "    print(k, type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 3.0585e-01, 2.1982e-02, 1.0366e-03, 2.2747e-02, 1.3149e-02,\n",
       "        0.0000e+00, 0.0000e+00, 5.3392e-04, 4.0292e-05, 1.0251e-04, 1.8690e-04,\n",
       "        2.0437e-03, 4.0239e-03, 4.9590e-05, 3.5405e-05, 3.8981e-05, 2.7299e-05,\n",
       "        3.9934e-05, 3.8742e-05, 6.1868e-05, 5.4358e-05, 3.1590e-05, 3.4809e-05,\n",
       "        8.4277e-05, 0.0000e+00, 6.2702e-05, 3.4570e-05, 4.5060e-05, 6.2941e-05,\n",
       "        5.5192e-05, 3.3616e-05, 5.4142e-04, 1.5900e-02, 2.2703e-01, 0.0000e+00,\n",
       "        5.4716e-05, 1.3267e-01, 8.1702e-03, 3.2782e-05, 3.7073e-05, 3.8265e-05,\n",
       "        3.6001e-05, 2.6106e-05, 1.6783e-04, 7.0212e-05, 6.6397e-05, 4.4822e-05,\n",
       "        0.0000e+00])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.batches[0]['losses'][:49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2, 40508, 32479,  ...,     0,     0,     0],\n",
       "        [    2, 13654,   196,  ...,     0,     0,     0],\n",
       "        [    2, 20029, 59364,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    2,  9349,  7377,  ...,     0,     0,     0],\n",
       "        [    2,  2382,  7914,  ...,     0,     0,     0],\n",
       "        [    2,  1297,   418,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.batches[0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0477e+01, -1.1675e+00, -1.4375e+00, -3.5794e-01, -1.8591e+00,\n",
       "          3.9068e-01, -2.2532e+00,  3.3258e-01, -1.3825e+00],\n",
       "        [ 3.9684e+00, -4.9718e-01, -2.9311e+00,  1.3824e+00, -1.6737e+00,\n",
       "          5.0959e+00, -1.3564e+00, -8.6886e-01, -3.3768e+00],\n",
       "        [ 1.1132e+00, -1.1276e+00, -2.5151e+00,  9.1764e-01, -1.1936e+00,\n",
       "          6.1062e+00,  1.2681e+00, -2.5758e+00, -2.4657e+00],\n",
       "        [ 8.0553e+00, -1.2848e+00, -1.9229e+00, -1.1450e+00, -3.6577e-01,\n",
       "          1.1940e-02, -1.7050e+00, -9.2705e-01, -1.4149e+00],\n",
       "        [ 1.8336e+00,  5.9974e+00,  2.0844e-01, -4.6786e-01, -1.0844e+00,\n",
       "         -1.5087e+00, -1.9922e+00, -1.0235e+00, -2.4271e+00],\n",
       "        [ 4.8394e-01,  1.0256e+00,  6.3280e+00, -2.3858e+00,  6.3513e-01,\n",
       "         -1.1173e+00, -1.3946e+00, -1.7036e+00, -1.3290e+00],\n",
       "        [ 9.7876e-01,  7.9919e-01,  5.5206e+00, -2.7252e+00,  5.1916e-01,\n",
       "         -9.8715e-01, -1.1156e+00, -1.5150e+00, -1.0666e+00],\n",
       "        [ 1.5994e+00,  3.2888e-01,  3.9372e+00, -2.1970e+00,  2.0518e-01,\n",
       "         -4.0224e-01, -8.9646e-01, -1.5107e+00, -7.8181e-01],\n",
       "        [ 8.6602e+00, -1.4622e+00, -9.9618e-01, -1.2920e+00, -6.9741e-01,\n",
       "         -4.1218e-01, -1.7485e+00, -3.6527e-01, -1.7306e+00],\n",
       "        [ 1.1043e+01, -1.1228e+00, -1.1303e+00, -1.1868e+00, -1.1465e+00,\n",
       "         -1.2156e+00, -2.2243e+00, -4.5571e-01, -1.6103e+00],\n",
       "        [ 1.0375e+01,  3.3371e-02, -1.2372e+00, -5.5622e-01, -1.9809e+00,\n",
       "         -1.5438e+00, -2.0507e+00, -2.5843e-01, -2.0089e+00],\n",
       "        [ 9.9967e+00,  6.1251e-01, -4.4555e-01, -7.6342e-01, -1.7397e+00,\n",
       "         -1.9121e+00, -2.2724e+00, -5.1899e-01, -2.0081e+00],\n",
       "        [ 5.2552e-01,  7.7978e+00,  2.9062e-02, -3.4304e-03, -1.1715e+00,\n",
       "         -8.5279e-01, -1.6611e+00, -1.3940e+00, -2.4061e+00],\n",
       "        [ 1.0500e+00,  5.7257e-01,  7.5936e+00, -2.1226e+00,  6.8473e-01,\n",
       "         -2.3902e+00, -9.7688e-01, -8.7566e-01, -9.4875e-01],\n",
       "        [ 1.0992e+01, -9.0481e-01, -1.1703e+00, -9.7830e-01, -1.6797e+00,\n",
       "         -8.5379e-01, -1.9926e+00, -1.1071e-01, -1.5036e+00],\n",
       "        [ 1.1260e+01, -1.0245e+00, -1.0678e+00, -8.6788e-01, -1.2190e+00,\n",
       "         -1.0538e+00, -2.0978e+00, -3.6135e-01, -1.7959e+00],\n",
       "        [ 1.1080e+01, -1.1875e+00, -1.1419e+00, -9.4132e-01, -1.5359e+00,\n",
       "         -1.3158e+00, -2.0159e+00, -3.6007e-01, -1.5689e+00],\n",
       "        [ 1.1460e+01, -1.2146e+00, -1.2845e+00, -1.1576e+00, -1.2333e+00,\n",
       "         -1.3778e+00, -2.4620e+00, -1.2706e-01, -1.6424e+00],\n",
       "        [ 1.1197e+01, -1.3321e+00, -1.3192e+00, -9.2055e-01, -1.2846e+00,\n",
       "         -1.0219e+00, -2.0833e+00,  1.0419e-02, -1.5308e+00],\n",
       "        [ 1.1173e+01, -1.4192e+00, -1.3675e+00, -8.8494e-01, -8.7436e-01,\n",
       "         -1.6947e+00, -1.8893e+00, -1.7130e-01, -1.4033e+00],\n",
       "        [ 1.0789e+01, -1.3581e+00, -1.6717e+00, -1.0882e+00, -5.2221e-01,\n",
       "         -1.7382e+00, -2.1035e+00, -1.5300e-01, -7.7139e-01],\n",
       "        [ 1.0816e+01, -1.3371e+00, -1.3367e+00, -1.2017e+00, -7.2650e-01,\n",
       "         -1.7581e+00, -2.2608e+00, -2.5509e-01, -1.0468e+00],\n",
       "        [ 1.1333e+01, -1.2091e+00, -1.3518e+00, -1.1178e+00, -9.7535e-01,\n",
       "         -1.3948e+00, -2.4912e+00, -2.1114e-01, -1.4345e+00],\n",
       "        [ 1.1192e+01, -1.2442e+00, -1.2226e+00, -9.6713e-01, -1.0088e+00,\n",
       "         -1.8195e+00, -2.1041e+00, -4.3087e-01, -1.3126e+00],\n",
       "        [ 1.0556e+01, -1.1764e+00, -1.5516e+00, -4.6905e-01, -1.1430e+00,\n",
       "         -1.5028e+00, -2.6481e+00,  2.7127e-01, -1.7774e+00],\n",
       "        [ 1.0140e+01, -1.3097e+00, -1.4635e+00, -5.4213e-01, -7.8512e-01,\n",
       "         -1.4842e+00, -2.3847e+00,  2.8363e-01, -1.5042e+00],\n",
       "        [ 1.0659e+01, -1.3924e+00, -1.6483e+00, -9.3261e-01, -5.5541e-01,\n",
       "         -1.8265e+00, -2.2733e+00, -4.2687e-01, -1.0803e+00],\n",
       "        [ 1.1315e+01, -1.1658e+00, -1.4598e+00, -8.1847e-01, -1.4297e+00,\n",
       "         -1.0020e+00, -2.6762e+00, -6.6640e-02, -1.4517e+00],\n",
       "        [ 1.1145e+01, -1.1344e+00, -1.2071e+00, -7.2702e-01, -1.8993e+00,\n",
       "         -1.1873e+00, -2.4161e+00,  2.0172e-01, -1.3875e+00],\n",
       "        [ 1.0941e+01, -1.1949e+00, -1.2637e+00, -8.1424e-01, -1.8606e+00,\n",
       "         -1.2099e+00, -2.2028e+00,  5.8303e-01, -1.7571e+00],\n",
       "        [ 1.0981e+01, -1.3096e+00, -1.4340e+00, -1.2315e+00, -1.3738e+00,\n",
       "         -1.5524e+00, -2.0720e+00,  4.5477e-01, -1.3051e+00],\n",
       "        [ 1.1326e+01, -1.3817e+00, -1.6314e+00, -7.3654e-01, -1.3672e+00,\n",
       "         -6.4751e-01, -2.2266e+00, -2.0909e-01, -1.7654e+00],\n",
       "        [ 9.3408e+00, -1.3364e+00, -1.6593e+00,  2.8438e-01, -1.5816e+00,\n",
       "          8.1274e-01, -1.6930e+00,  4.9772e-01, -2.2797e+00],\n",
       "        [ 1.8027e+00, -5.2676e-01, -2.5923e+00,  9.2172e-01, -1.5847e+00,\n",
       "          6.5307e+00,  1.9532e-01, -1.3206e+00, -2.8005e+00],\n",
       "        [ 1.9508e+00, -1.5050e+00, -2.5035e+00,  1.7936e-01, -2.9317e-01,\n",
       "          4.9103e+00,  3.2200e+00, -1.9371e+00, -2.0439e+00],\n",
       "        [ 1.2372e+00, -1.1621e+00, -2.2246e+00,  2.0610e-01, -5.5458e-01,\n",
       "          5.0968e+00,  2.9783e+00, -1.9303e+00, -2.4847e+00],\n",
       "        [ 1.0964e+01, -1.6649e+00, -1.6598e+00, -8.6443e-01, -9.6408e-01,\n",
       "          8.1818e-02, -1.6074e+00, -7.0756e-01, -1.6062e+00],\n",
       "        [ 5.7608e+00, -1.4615e+00, -1.7996e+00,  4.3657e-01, -1.3869e+00,\n",
       "          3.7056e+00,  3.5862e-01, -5.1216e-01, -1.8185e+00],\n",
       "        [ 7.2672e+00, -1.7909e+00, -1.8112e+00, -1.3295e+00,  4.8054e-01,\n",
       "          1.2849e+00,  1.6342e+00, -1.7979e+00, -4.5337e-01],\n",
       "        [ 1.1274e+01, -1.0367e+00, -1.2234e+00, -1.1109e+00, -1.1495e+00,\n",
       "         -1.2372e+00, -2.2284e+00, -4.0864e-01, -1.4931e+00],\n",
       "        [ 1.1238e+01, -1.1347e+00, -1.1973e+00, -8.7685e-01, -1.5315e+00,\n",
       "         -1.1504e+00, -2.2127e+00, -3.9954e-02, -1.7495e+00],\n",
       "        [ 1.1140e+01, -1.2298e+00, -1.2361e+00, -1.3280e+00, -1.3179e+00,\n",
       "         -1.5064e+00, -2.1148e+00, -2.7883e-02, -1.6271e+00],\n",
       "        [ 1.1148e+01, -1.3106e+00, -1.1571e+00, -1.2545e+00, -1.1773e+00,\n",
       "         -1.3960e+00, -2.2719e+00, -2.8255e-01, -1.5063e+00],\n",
       "        [ 1.1542e+01, -7.7267e-01, -1.4201e+00, -1.1188e+00, -1.4773e+00,\n",
       "         -1.4217e+00, -2.4065e+00, -9.8159e-02, -1.7588e+00],\n",
       "        [ 1.0006e+01, -8.2944e-01, -1.2661e+00, -4.4894e-01, -1.7501e+00,\n",
       "         -1.5135e+00, -2.0048e+00,  5.6988e-01, -2.7113e+00],\n",
       "        [ 1.0608e+01, -1.2487e+00, -1.0980e+00, -1.7656e+00, -1.2347e-01,\n",
       "         -1.9097e+00, -1.8148e+00, -7.1745e-01, -9.8738e-01],\n",
       "        [ 1.0637e+01, -1.2143e+00, -9.4008e-01, -1.6952e+00, -3.6845e-01,\n",
       "         -1.8022e+00, -2.0237e+00, -6.7975e-01, -9.2728e-01],\n",
       "        [ 1.1122e+01, -1.5970e+00, -1.8023e+00, -7.2301e-01, -1.3139e+00,\n",
       "         -1.1059e-01, -2.4161e+00, -2.6325e-01, -1.7683e+00],\n",
       "        [ 5.0499e+00, -3.1937e-01, -7.3200e-01,  5.3392e-01, -5.0357e-01,\n",
       "          8.3650e-01, -1.0674e-01,  6.1785e-01, -1.3093e+00]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.batches[0]['logits'][0][:49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 256])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.batches[0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import torch\n",
    "from typing import List\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "@dataclass\n",
    "class SentenceData:\n",
    "    input_ids: torch.Tensor\n",
    "    attention_mask: torch.Tensor\n",
    "    last_hidden_states: torch.Tensor\n",
    "    losses: torch.Tensor\n",
    "    logits: torch.Tensor\n",
    "    labels: torch.Tensor\n",
    "    \n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BatchData:\n",
    "    input_ids: torch.Tensor\n",
    "    attention_mask: torch.Tensor\n",
    "    last_hidden_states: torch.Tensor\n",
    "    losses: torch.Tensor\n",
    "    logits: torch.Tensor\n",
    "    labels: torch.Tensor\n",
    "\n",
    "    def detach(self):\n",
    "        \"\"\"Detach all tensors to move them to CPU and reduce memory footprint on GPU.\"\"\"\n",
    "        for attr, value in self.__dict__.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                setattr(self, attr, value.detach().cpu())\n",
    "            elif isinstance(value, tuple) and all(torch.is_tensor(x) for x in value):\n",
    "                # If the batch is a tuple of tensors (like hidden states), process each tensor.\n",
    "                detached_batch = tuple(layer.detach().cpu() for layer in value)\n",
    "                setattr(self, attr, detached_batch)\n",
    "            else:\n",
    "                raise TypeError(\"Unsupported batch type: {}\".format(type(value)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_model_output(data_loader, model, device):\n",
    "    model.eval()\n",
    "    processed_batches = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(data_loader):\n",
    "            data = {k: v.to(device) for k, v in data.items()}\n",
    "            outputs = model(**data)\n",
    "            batch = BatchData(\n",
    "                input_ids=data['input_ids'],\n",
    "                attention_mask=data['attention_mask'],\n",
    "                last_hidden_states=outputs['last_hidden_state'],\n",
    "                losses=outputs['losses'],\n",
    "                logits=outputs['logits'],\n",
    "                labels=data['labels'],\n",
    "            )\n",
    "            batch.detach()\n",
    "            processed_batches.append(batch)\n",
    "    return processed_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548a5a77cdce402d824044ef5d695117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "data_loader = training_outputs.test_dataloader\n",
    "device = torch.device('cpu')\n",
    "processed_batches = process_model_output(data_loader, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = processed_batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({False: 207, True: 49})\n",
      "Counter({False: 220, True: 36})\n",
      "Counter({False: 236, True: 20})\n",
      "Counter({False: 232, True: 24})\n",
      "Counter({False: 225, True: 31})\n",
      "Counter({False: 222, True: 34})\n",
      "Counter({False: 186, True: 70})\n",
      "Counter({False: 218, True: 38})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "for idx in range(batch.input_ids.size(0)):  # Iterate over each sentence in the batch\n",
    "        sentence_mask = batch.input_ids[idx] != 0\n",
    "        print(Counter(sentence_mask.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "49+36+20+24+31+34+70+38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchData(input_ids=tensor([[    2, 40508, 32479,  ...,     0,     0,     0],\n",
       "        [    2, 13654,   196,  ...,     0,     0,     0],\n",
       "        [    2, 20029, 59364,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    2,  9349,  7377,  ...,     0,     0,     0],\n",
       "        [    2,  2382,  7914,  ...,     0,     0,     0],\n",
       "        [    2,  1297,   418,  ...,     0,     0,     0]]), attention_mask=tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), last_hidden_states=tensor([[[ 0.4485,  0.0872, -1.0895,  ...,  0.4254,  1.9157,  0.0821],\n",
       "         [ 1.1693,  0.6690, -0.5932,  ..., -0.2493,  0.4333,  0.3624],\n",
       "         [ 1.0068,  1.5909, -0.1440,  ..., -0.5593,  0.0276,  1.1869],\n",
       "         ...,\n",
       "         [ 0.0570, -0.1871, -0.6887,  ...,  1.0239,  1.0818, -0.1652],\n",
       "         [-0.0700,  0.3262, -0.6664,  ...,  1.0465,  1.4056,  0.0026],\n",
       "         [-0.3478,  0.3988, -0.6688,  ...,  1.1104,  1.4648,  0.2855]],\n",
       "\n",
       "        [[ 0.0740, -0.5042, -1.0174,  ...,  0.3579,  1.4507,  0.0925],\n",
       "         [ 0.4654,  0.5753, -0.6203,  ...,  0.5398,  0.5164,  0.1562],\n",
       "         [ 0.2614, -0.6558, -0.8791,  ...,  0.2369,  0.8864, -0.5782],\n",
       "         ...,\n",
       "         [-0.2050, -0.1250, -0.7854,  ...,  0.3947,  0.3013,  0.0790],\n",
       "         [-0.2798, -0.2760, -0.7498,  ...,  0.1746,  0.6232, -0.0417],\n",
       "         [-0.0805, -0.0512, -0.7671,  ...,  0.1803,  0.6330,  0.0317]],\n",
       "\n",
       "        [[ 0.2658, -0.4669, -0.5442,  ...,  0.8579,  0.8050,  0.0657],\n",
       "         [ 0.2087,  0.2782, -0.2375,  ...,  0.8685,  1.0566, -0.1303],\n",
       "         [-0.5010, -1.5309, -0.4511,  ...,  0.2262,  1.0789, -0.7253],\n",
       "         ...,\n",
       "         [-0.5118, -0.4218, -0.3286,  ...,  0.8366,  0.8547, -0.2341],\n",
       "         [-0.3198, -0.3225, -0.1424,  ...,  0.9027,  0.6842, -0.1105],\n",
       "         [-0.2002, -0.3025, -0.2078,  ...,  0.7921,  0.7240, -0.2572]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.8500,  0.2310, -1.1121,  ...,  0.9688,  1.9994,  0.5976],\n",
       "         [ 0.8447,  0.3458, -1.3988,  ...,  0.6754,  1.0553, -0.1030],\n",
       "         [ 0.8366,  0.2898, -1.6170,  ...,  0.4556,  0.9501, -0.0310],\n",
       "         ...,\n",
       "         [ 0.0487, -0.1800, -0.9381,  ...,  0.9539,  1.4347,  0.5368],\n",
       "         [ 0.3597, -0.0794, -1.0199,  ...,  0.6877,  1.4493,  0.2807],\n",
       "         [ 0.0152,  0.0385, -0.9038,  ...,  0.4420,  1.9544,  0.0591]],\n",
       "\n",
       "        [[ 0.3162, -0.0777, -0.8094,  ...,  0.2340,  1.6686, -0.2790],\n",
       "         [ 0.8098,  0.5352, -1.2081,  ..., -0.2551,  1.3514, -0.1657],\n",
       "         [-0.3905,  0.7672, -1.3585,  ...,  0.0655,  1.0225, -0.5938],\n",
       "         ...,\n",
       "         [ 0.0842, -0.1314, -0.1940,  ...,  0.6174,  0.9949,  0.0064],\n",
       "         [-0.0517, -0.2111, -0.3371,  ...,  0.4493,  0.9715, -0.0487],\n",
       "         [-0.0638, -0.2021, -0.2648,  ...,  0.5149,  0.9387, -0.1217]],\n",
       "\n",
       "        [[ 0.3300,  0.0798, -0.4918,  ...,  0.2693,  1.8239, -0.0974],\n",
       "         [-0.3712,  0.5679, -0.8325,  ...,  0.1722,  2.0062, -0.2199],\n",
       "         [-0.0498, -0.1236, -0.8696,  ..., -0.3541,  1.7448, -0.3049],\n",
       "         ...,\n",
       "         [-0.1081,  0.3590, -0.6765,  ...,  0.0540,  1.2537, -0.2565],\n",
       "         [-0.0835,  0.4205, -0.5110,  ...,  0.2432,  0.9210, -0.1193],\n",
       "         [ 0.0984,  0.2753, -0.4976,  ...,  0.2870,  0.5976, -0.1201]]]), losses=tensor([0.0000, 0.3058, 0.0220,  ..., 0.0000, 0.0000, 0.0000]), logits=tensor([[[10.4765, -1.1675, -1.4375,  ..., -2.2532,  0.3326, -1.3825],\n",
       "         [ 3.9684, -0.4972, -2.9311,  ..., -1.3564, -0.8689, -3.3768],\n",
       "         [ 1.1132, -1.1276, -2.5151,  ...,  1.2681, -2.5758, -2.4657],\n",
       "         ...,\n",
       "         [ 9.3841, -1.2185, -2.1669,  ..., -1.9985,  0.5565, -2.2057],\n",
       "         [ 9.1797, -1.8767, -1.9494,  ..., -0.7936,  0.0269, -1.9204],\n",
       "         [ 8.9314, -1.8663, -1.8455,  ..., -0.1519, -0.1536, -1.7841]],\n",
       "\n",
       "        [[11.1567, -0.6830, -1.4609,  ..., -2.7124,  0.1401, -1.4511],\n",
       "         [ 7.7504,  0.4739, -0.7714,  ..., -2.1905,  0.0535, -1.9884],\n",
       "         [ 8.9092,  0.6142, -0.7159,  ..., -2.5696,  0.4288, -2.2659],\n",
       "         ...,\n",
       "         [10.5424, -0.8758, -1.9875,  ..., -3.1675,  0.4538, -1.5012],\n",
       "         [11.2409, -0.6063, -1.8254,  ..., -3.3892,  0.5410, -1.3890],\n",
       "         [10.9398, -0.8168, -1.8430,  ..., -3.2664,  0.6056, -1.0936]],\n",
       "\n",
       "        [[10.3209, -0.2732, -1.1702,  ..., -3.1147,  0.4703, -0.7939],\n",
       "         [ 8.8825,  0.4299, -1.9850,  ..., -3.3916,  0.5288, -1.7437],\n",
       "         [ 9.0966,  0.7126, -1.2500,  ..., -2.6222, -0.1583, -2.0406],\n",
       "         ...,\n",
       "         [ 9.9408, -0.6547, -2.0270,  ..., -3.0770,  0.7150, -0.9395],\n",
       "         [ 9.8598, -0.4764, -2.0821,  ..., -3.3200,  0.7490, -1.0893],\n",
       "         [10.1148, -0.3491, -1.9444,  ..., -3.4375,  0.7338, -1.1713]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 9.4315, -1.3513, -1.9344,  ..., -1.3127,  0.7815, -1.7548],\n",
       "         [ 8.9623, -1.6655, -2.0746,  ..., -1.5519,  0.8128, -2.1757],\n",
       "         [ 8.4800, -1.5460, -1.7338,  ..., -1.4270,  0.6617, -2.2859],\n",
       "         ...,\n",
       "         [ 9.9718, -1.6028, -2.2513,  ..., -2.6299,  0.6675, -1.7461],\n",
       "         [10.4664, -1.4725, -2.1479,  ..., -2.4419,  0.5307, -1.6121],\n",
       "         [10.7398, -1.7081, -1.6711,  ..., -2.0899,  0.1719, -1.5401]],\n",
       "\n",
       "        [[11.3000, -0.5876, -1.3668,  ..., -2.9226,  0.6464, -1.1181],\n",
       "         [10.3151, -0.5532, -1.9559,  ..., -3.4082,  0.9274, -1.4527],\n",
       "         [10.5327, -1.1243, -1.5542,  ..., -2.2397,  0.2689, -1.7538],\n",
       "         ...,\n",
       "         [ 9.1596,  0.3045,  0.2575,  ..., -3.0045, -0.0299, -1.6552],\n",
       "         [ 9.8840,  0.2944, -0.5594,  ..., -3.1543,  0.0198, -1.8197],\n",
       "         [ 9.8495,  0.1639, -0.3759,  ..., -3.1446,  0.0179, -1.6702]],\n",
       "\n",
       "        [[10.8502, -0.7520, -1.3559,  ..., -2.7812,  0.8815, -1.0450],\n",
       "         [10.6949, -0.8262, -1.7489,  ..., -2.8657,  0.4529, -1.3873],\n",
       "         [10.4897, -1.1858, -1.3286,  ..., -2.3119, -0.0247, -1.3452],\n",
       "         ...,\n",
       "         [10.8631, -1.0300, -2.1020,  ..., -2.8896,  0.7656, -1.2405],\n",
       "         [10.6960, -1.0426, -2.3101,  ..., -3.1377,  0.8471, -1.2382],\n",
       "         [10.7076, -1.0140, -2.3964,  ..., -3.1799,  0.7032, -1.4396]]]), labels=tensor([[-100,    5,    5,  ..., -100, -100, -100],\n",
       "        [-100,    1, -100,  ..., -100, -100, -100],\n",
       "        [-100,    0,    0,  ..., -100, -100, -100],\n",
       "        ...,\n",
       "        [-100,    0,    0,  ..., -100, -100, -100],\n",
       "        [-100,    0,    0,  ..., -100, -100, -100],\n",
       "        [-100,    0,    0,  ..., -100, -100, -100]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e016b51e59094202b57b9cffebe5bfcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_sentences = []\n",
    "for batch in tqdm(processed_batches):\n",
    "    sentences = extract_sentences_from_batch(batch)\n",
    "    all_sentences.extend(sentences)  # Collect all sentences from all batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_model_output(data_loader, model, device):\n",
    "    model.eval()\n",
    "    processed_batches = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(data_loader):\n",
    "            data = {k: v.to(device) for k, v in data.items()}\n",
    "            outputs = model(**data)\n",
    "            batch = BatchData(\n",
    "                input_ids=data['input_ids'],\n",
    "                attention_mask=data['attention_mask'],\n",
    "                last_hidden_states=outputs['last_hidden_state'],\n",
    "                losses=outputs['losses'],\n",
    "                logits=outputs['logits'],\n",
    "                labels=data['labels'],\n",
    "            )\n",
    "            batch.detach()\n",
    "            processed_batches.append(batch)\n",
    "    return processed_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOutputProcessor:\n",
    "    def __init__(self, data_loader, model, device):\n",
    "        self.data_loader = data_loader\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "    def process_outputs(self):\n",
    "        self.model.eval()\n",
    "        sentences = []\n",
    "        with torch.no_grad():\n",
    "            for data in tqdm(self.data_loader):\n",
    "                data = {k: v.to(self.device) for k, v in data.items()}\n",
    "                outputs = self.model(**data)\n",
    "                batch = BatchData(\n",
    "                    input_ids=data['input_ids'],\n",
    "                    attention_mask=data['attention_mask'],\n",
    "                    last_hidden_states=outputs['last_hidden_state'],\n",
    "                    losses=outputs['losses'],\n",
    "                    logits=outputs['logits'],\n",
    "                    labels=data['labels'],\n",
    "                )\n",
    "                batch.detach()\n",
    "                sentences = self.extract_sentences_from_batch(batch)\n",
    "                all_sentences.extend(sentences)\n",
    "        return sentences\n",
    "\n",
    "    def extract_sentences_from_batch(batch: BatchData):\n",
    "        sentences = []\n",
    "\n",
    "        loss_start_idx = 0\n",
    "        unique_values, indices = torch.unique(\n",
    "            batch.input_ids, return_inverse=True\n",
    "        )\n",
    "        active_losses = batch.losses[indices.view(-1) != 0]\n",
    "        for idx in range(batch.input_ids.size(0)):  # Iterate over each sentence in the batch\n",
    "            sentence_mask = batch.input_ids[idx] != 0  # Create a mask where the input_ids are not padding\n",
    "\n",
    "            # Use the mask to filter out padding in attention_mask, last_hidden_state, logits, labels\n",
    "            if sentence_mask.any():\n",
    "                input_ids = batch.input_ids[idx][sentence_mask]\n",
    "                attention_mask = batch.attention_mask[idx][sentence_mask]\n",
    "                last_hidden_state = batch.last_hidden_states[idx][sentence_mask]\n",
    "                logits = batch.logits[idx][sentence_mask]\n",
    "                label = batch.labels[idx][sentence_mask]\n",
    "                actual_token_count = sentence_mask.sum()  # Number of non-padding tokens\n",
    "                sentence_loss = active_losses[loss_start_idx:loss_start_idx + actual_token_count]\n",
    "                loss_start_idx += actual_token_count\n",
    "                sentence = SentenceData(\n",
    "                                input_ids=input_ids,\n",
    "                                attention_mask=attention_mask,\n",
    "                                last_hidden_states=last_hidden_state,\n",
    "                                losses=sentence_loss,\n",
    "                                logits=logits,\n",
    "                                labels=label\n",
    "                            )\n",
    "                sentences.append(sentence)\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceData(input_ids=tensor([    2, 40508, 32479,    19, 33014, 34675, 43752,   466,    19,  2279,\n",
       "        25896,  1089,  1098,  1161,   921,  7410, 16661,   306,  2767,  4119,\n",
       "        19020, 31490,  8500, 10926, 18694,  1000, 13567,   139,  2801,  3011,\n",
       "         7996,   305,  7377, 40508, 50014,   197,   305, 26258,  2050,   492,\n",
       "         3812,  6700, 18112,   306,  9520,  2657, 20195,    20,     3]), attention_mask=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1]), last_hidden_states=tensor([[ 0.4485,  0.0872, -1.0895,  ...,  0.4254,  1.9157,  0.0821],\n",
       "        [ 1.1693,  0.6690, -0.5932,  ..., -0.2493,  0.4333,  0.3624],\n",
       "        [ 1.0068,  1.5909, -0.1440,  ..., -0.5593,  0.0276,  1.1869],\n",
       "        ...,\n",
       "        [ 0.1431, -0.9956, -1.0887,  ...,  0.4026,  1.4030, -0.3296],\n",
       "        [ 0.3733, -0.0979, -1.0433,  ...,  0.2927,  1.6223, -0.0199],\n",
       "        [ 1.4138,  0.5393, -0.8346,  ..., -0.0449,  2.3642, -0.0133]]), losses=tensor([0.0000e+00, 3.0585e-01, 2.1982e-02, 1.0366e-03, 2.2747e-02, 1.3149e-02,\n",
       "        0.0000e+00, 0.0000e+00, 5.3392e-04, 4.0292e-05, 1.0251e-04, 1.8690e-04,\n",
       "        2.0437e-03, 4.0239e-03, 4.9590e-05, 3.5405e-05, 3.8981e-05, 2.7299e-05,\n",
       "        3.9934e-05, 3.8742e-05, 6.1868e-05, 5.4358e-05, 3.1590e-05, 3.4809e-05,\n",
       "        8.4277e-05, 0.0000e+00, 6.2702e-05, 3.4570e-05, 4.5060e-05, 6.2941e-05,\n",
       "        5.5192e-05, 3.3616e-05, 5.4142e-04, 1.5900e-02, 2.2703e-01, 0.0000e+00,\n",
       "        5.4716e-05, 1.3267e-01, 8.1702e-03, 3.2782e-05, 3.7073e-05, 3.8265e-05,\n",
       "        3.6001e-05, 2.6106e-05, 1.6783e-04, 7.0212e-05, 6.6397e-05, 4.4822e-05,\n",
       "        0.0000e+00]), logits=tensor([[ 1.0477e+01, -1.1675e+00, -1.4375e+00, -3.5794e-01, -1.8591e+00,\n",
       "          3.9068e-01, -2.2532e+00,  3.3258e-01, -1.3825e+00],\n",
       "        [ 3.9684e+00, -4.9718e-01, -2.9311e+00,  1.3824e+00, -1.6737e+00,\n",
       "          5.0959e+00, -1.3564e+00, -8.6886e-01, -3.3768e+00],\n",
       "        [ 1.1132e+00, -1.1276e+00, -2.5151e+00,  9.1764e-01, -1.1936e+00,\n",
       "          6.1062e+00,  1.2681e+00, -2.5758e+00, -2.4657e+00],\n",
       "        [ 8.0553e+00, -1.2848e+00, -1.9229e+00, -1.1450e+00, -3.6577e-01,\n",
       "          1.1940e-02, -1.7050e+00, -9.2705e-01, -1.4149e+00],\n",
       "        [ 1.8336e+00,  5.9974e+00,  2.0844e-01, -4.6786e-01, -1.0844e+00,\n",
       "         -1.5087e+00, -1.9922e+00, -1.0235e+00, -2.4271e+00],\n",
       "        [ 4.8394e-01,  1.0256e+00,  6.3280e+00, -2.3858e+00,  6.3513e-01,\n",
       "         -1.1173e+00, -1.3946e+00, -1.7036e+00, -1.3290e+00],\n",
       "        [ 9.7876e-01,  7.9919e-01,  5.5206e+00, -2.7252e+00,  5.1916e-01,\n",
       "         -9.8715e-01, -1.1156e+00, -1.5150e+00, -1.0666e+00],\n",
       "        [ 1.5994e+00,  3.2888e-01,  3.9372e+00, -2.1970e+00,  2.0518e-01,\n",
       "         -4.0224e-01, -8.9646e-01, -1.5107e+00, -7.8181e-01],\n",
       "        [ 8.6602e+00, -1.4622e+00, -9.9618e-01, -1.2920e+00, -6.9741e-01,\n",
       "         -4.1218e-01, -1.7485e+00, -3.6527e-01, -1.7306e+00],\n",
       "        [ 1.1043e+01, -1.1228e+00, -1.1303e+00, -1.1868e+00, -1.1465e+00,\n",
       "         -1.2156e+00, -2.2243e+00, -4.5571e-01, -1.6103e+00],\n",
       "        [ 1.0375e+01,  3.3371e-02, -1.2372e+00, -5.5622e-01, -1.9809e+00,\n",
       "         -1.5438e+00, -2.0507e+00, -2.5843e-01, -2.0089e+00],\n",
       "        [ 9.9967e+00,  6.1251e-01, -4.4555e-01, -7.6342e-01, -1.7397e+00,\n",
       "         -1.9121e+00, -2.2724e+00, -5.1899e-01, -2.0081e+00],\n",
       "        [ 5.2552e-01,  7.7978e+00,  2.9062e-02, -3.4304e-03, -1.1715e+00,\n",
       "         -8.5279e-01, -1.6611e+00, -1.3940e+00, -2.4061e+00],\n",
       "        [ 1.0500e+00,  5.7257e-01,  7.5936e+00, -2.1226e+00,  6.8473e-01,\n",
       "         -2.3902e+00, -9.7688e-01, -8.7566e-01, -9.4875e-01],\n",
       "        [ 1.0992e+01, -9.0481e-01, -1.1703e+00, -9.7830e-01, -1.6797e+00,\n",
       "         -8.5379e-01, -1.9926e+00, -1.1071e-01, -1.5036e+00],\n",
       "        [ 1.1260e+01, -1.0245e+00, -1.0678e+00, -8.6788e-01, -1.2190e+00,\n",
       "         -1.0538e+00, -2.0978e+00, -3.6135e-01, -1.7959e+00],\n",
       "        [ 1.1080e+01, -1.1875e+00, -1.1419e+00, -9.4132e-01, -1.5359e+00,\n",
       "         -1.3158e+00, -2.0159e+00, -3.6007e-01, -1.5689e+00],\n",
       "        [ 1.1460e+01, -1.2146e+00, -1.2845e+00, -1.1576e+00, -1.2333e+00,\n",
       "         -1.3778e+00, -2.4620e+00, -1.2706e-01, -1.6424e+00],\n",
       "        [ 1.1197e+01, -1.3321e+00, -1.3192e+00, -9.2055e-01, -1.2846e+00,\n",
       "         -1.0219e+00, -2.0833e+00,  1.0419e-02, -1.5308e+00],\n",
       "        [ 1.1173e+01, -1.4192e+00, -1.3675e+00, -8.8494e-01, -8.7436e-01,\n",
       "         -1.6947e+00, -1.8893e+00, -1.7130e-01, -1.4033e+00],\n",
       "        [ 1.0789e+01, -1.3581e+00, -1.6717e+00, -1.0882e+00, -5.2221e-01,\n",
       "         -1.7382e+00, -2.1035e+00, -1.5300e-01, -7.7139e-01],\n",
       "        [ 1.0816e+01, -1.3371e+00, -1.3367e+00, -1.2017e+00, -7.2650e-01,\n",
       "         -1.7581e+00, -2.2608e+00, -2.5509e-01, -1.0468e+00],\n",
       "        [ 1.1333e+01, -1.2091e+00, -1.3518e+00, -1.1178e+00, -9.7535e-01,\n",
       "         -1.3948e+00, -2.4912e+00, -2.1114e-01, -1.4345e+00],\n",
       "        [ 1.1192e+01, -1.2442e+00, -1.2226e+00, -9.6713e-01, -1.0088e+00,\n",
       "         -1.8195e+00, -2.1041e+00, -4.3087e-01, -1.3126e+00],\n",
       "        [ 1.0556e+01, -1.1764e+00, -1.5516e+00, -4.6905e-01, -1.1430e+00,\n",
       "         -1.5028e+00, -2.6481e+00,  2.7127e-01, -1.7774e+00],\n",
       "        [ 1.0140e+01, -1.3097e+00, -1.4635e+00, -5.4213e-01, -7.8512e-01,\n",
       "         -1.4842e+00, -2.3847e+00,  2.8363e-01, -1.5042e+00],\n",
       "        [ 1.0659e+01, -1.3924e+00, -1.6483e+00, -9.3261e-01, -5.5541e-01,\n",
       "         -1.8265e+00, -2.2733e+00, -4.2687e-01, -1.0803e+00],\n",
       "        [ 1.1315e+01, -1.1658e+00, -1.4598e+00, -8.1847e-01, -1.4297e+00,\n",
       "         -1.0020e+00, -2.6762e+00, -6.6640e-02, -1.4517e+00],\n",
       "        [ 1.1145e+01, -1.1344e+00, -1.2071e+00, -7.2702e-01, -1.8993e+00,\n",
       "         -1.1873e+00, -2.4161e+00,  2.0172e-01, -1.3875e+00],\n",
       "        [ 1.0941e+01, -1.1949e+00, -1.2637e+00, -8.1424e-01, -1.8606e+00,\n",
       "         -1.2099e+00, -2.2028e+00,  5.8303e-01, -1.7571e+00],\n",
       "        [ 1.0981e+01, -1.3096e+00, -1.4340e+00, -1.2315e+00, -1.3738e+00,\n",
       "         -1.5524e+00, -2.0720e+00,  4.5477e-01, -1.3051e+00],\n",
       "        [ 1.1326e+01, -1.3817e+00, -1.6314e+00, -7.3654e-01, -1.3672e+00,\n",
       "         -6.4751e-01, -2.2266e+00, -2.0909e-01, -1.7654e+00],\n",
       "        [ 9.3408e+00, -1.3364e+00, -1.6593e+00,  2.8438e-01, -1.5816e+00,\n",
       "          8.1274e-01, -1.6930e+00,  4.9772e-01, -2.2797e+00],\n",
       "        [ 1.8027e+00, -5.2676e-01, -2.5923e+00,  9.2172e-01, -1.5847e+00,\n",
       "          6.5307e+00,  1.9532e-01, -1.3206e+00, -2.8005e+00],\n",
       "        [ 1.9508e+00, -1.5050e+00, -2.5035e+00,  1.7936e-01, -2.9317e-01,\n",
       "          4.9103e+00,  3.2200e+00, -1.9371e+00, -2.0439e+00],\n",
       "        [ 1.2372e+00, -1.1621e+00, -2.2246e+00,  2.0610e-01, -5.5458e-01,\n",
       "          5.0968e+00,  2.9783e+00, -1.9303e+00, -2.4847e+00],\n",
       "        [ 1.0964e+01, -1.6649e+00, -1.6598e+00, -8.6443e-01, -9.6408e-01,\n",
       "          8.1818e-02, -1.6074e+00, -7.0756e-01, -1.6062e+00],\n",
       "        [ 5.7608e+00, -1.4615e+00, -1.7996e+00,  4.3657e-01, -1.3869e+00,\n",
       "          3.7056e+00,  3.5862e-01, -5.1216e-01, -1.8185e+00],\n",
       "        [ 7.2672e+00, -1.7909e+00, -1.8112e+00, -1.3295e+00,  4.8054e-01,\n",
       "          1.2849e+00,  1.6342e+00, -1.7979e+00, -4.5337e-01],\n",
       "        [ 1.1274e+01, -1.0367e+00, -1.2234e+00, -1.1109e+00, -1.1495e+00,\n",
       "         -1.2372e+00, -2.2284e+00, -4.0864e-01, -1.4931e+00],\n",
       "        [ 1.1238e+01, -1.1347e+00, -1.1973e+00, -8.7685e-01, -1.5315e+00,\n",
       "         -1.1504e+00, -2.2127e+00, -3.9954e-02, -1.7495e+00],\n",
       "        [ 1.1140e+01, -1.2298e+00, -1.2361e+00, -1.3280e+00, -1.3179e+00,\n",
       "         -1.5064e+00, -2.1148e+00, -2.7883e-02, -1.6271e+00],\n",
       "        [ 1.1148e+01, -1.3106e+00, -1.1571e+00, -1.2545e+00, -1.1773e+00,\n",
       "         -1.3960e+00, -2.2719e+00, -2.8255e-01, -1.5063e+00],\n",
       "        [ 1.1542e+01, -7.7267e-01, -1.4201e+00, -1.1188e+00, -1.4773e+00,\n",
       "         -1.4217e+00, -2.4065e+00, -9.8159e-02, -1.7588e+00],\n",
       "        [ 1.0006e+01, -8.2944e-01, -1.2661e+00, -4.4894e-01, -1.7501e+00,\n",
       "         -1.5135e+00, -2.0048e+00,  5.6988e-01, -2.7113e+00],\n",
       "        [ 1.0608e+01, -1.2487e+00, -1.0980e+00, -1.7656e+00, -1.2347e-01,\n",
       "         -1.9097e+00, -1.8148e+00, -7.1745e-01, -9.8738e-01],\n",
       "        [ 1.0637e+01, -1.2143e+00, -9.4008e-01, -1.6952e+00, -3.6845e-01,\n",
       "         -1.8022e+00, -2.0237e+00, -6.7975e-01, -9.2728e-01],\n",
       "        [ 1.1122e+01, -1.5970e+00, -1.8023e+00, -7.2301e-01, -1.3139e+00,\n",
       "         -1.1059e-01, -2.4161e+00, -2.6325e-01, -1.7683e+00],\n",
       "        [ 5.0499e+00, -3.1937e-01, -7.3200e-01,  5.3392e-01, -5.0357e-01,\n",
       "          8.3650e-01, -1.0674e-01,  6.1785e-01, -1.3093e+00]]), labels=tensor([-100,    5,    5,    0,    1,    2, -100, -100,    0,    0,    0,    0,\n",
       "           1,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0, -100,    0,    0,    0,    0,    0,    0,    0,    5,    5, -100,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "        -100]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelOutputProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 3.0585e-01, 2.1982e-02, 1.0366e-03, 2.2747e-02, 1.3149e-02,\n",
       "        0.0000e+00, 0.0000e+00, 5.3392e-04, 4.0292e-05, 1.0251e-04, 1.8690e-04,\n",
       "        2.0437e-03, 4.0239e-03, 4.9590e-05, 3.5405e-05, 3.8981e-05, 2.7299e-05,\n",
       "        3.9934e-05, 3.8742e-05, 6.1868e-05, 5.4358e-05, 3.1590e-05, 3.4809e-05,\n",
       "        8.4277e-05, 0.0000e+00, 6.2702e-05, 3.4570e-05, 4.5060e-05, 6.2941e-05,\n",
       "        5.5192e-05, 3.3616e-05, 5.4142e-04, 1.5900e-02, 2.2703e-01, 0.0000e+00,\n",
       "        5.4716e-05, 1.3267e-01, 8.1702e-03, 3.2782e-05, 3.7073e-05, 3.8265e-05,\n",
       "        3.6001e-05, 2.6106e-05, 1.6783e-04, 7.0212e-05, 6.6397e-05, 4.4822e-05,\n",
       "        0.0000e+00])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0].losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m BatchOutputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39moutputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m      2\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m ModelOutputs(batch_outputs)\n\u001b[1;32m      3\u001b[0m results \u001b[38;5;241m=\u001b[39m ModelResults(outputs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "batch_outputs = BatchOutputs(self.outputs, self.model)\n",
    "model_outputs = ModelOutputs(batch_outputs)\n",
    "results = ModelResults(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
